{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VzFGp1u_cwgz"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3cmQyaz2c0aR"
      },
      "source": [
        "This notebook runs Valentine matchers on test data generated from the SANTOS data lake tables."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Download the SANTOS labeled benchmark.\n",
        "2. The data lake tables -- in the `datalake` directory -- are the tables to be sampled. Update the `table_dir` variable under the *Cluster Tables* section to point to this directory, relative to this notebook.\n",
        "3. The test results are written to separate `.csv` files for each matcher. Update the `matcher_out_dir` and `matcher_out` variables under the *Valentine Tests* section to the desired output files."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wf555dpDc1wk"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aexhExTqcV4n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from valentine import valentine_match, valentine_metrics\n",
        "from valentine.algorithms import Coma, Cupid, DistributionBased, JaccardLevenMatcher, SimilarityFlooding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2LGs_5_dBgA"
      },
      "source": [
        "# Cluster Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sk6rgWSdDDL",
        "outputId": "b212c2c5-81a0-462a-eae8-ec527d42d422"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['311_calls_historic_data',\n",
              " 'abandoned_wells',\n",
              " 'albums',\n",
              " 'animal_tag_data',\n",
              " 'biodiversity',\n",
              " 'business_rates',\n",
              " 'cdc_nutrition_physical_activity_and_obesity_legislation',\n",
              " 'cihr_co-applicant',\n",
              " 'civic_building_locations',\n",
              " 'complaint_by_practice',\n",
              " 'contributors_parties',\n",
              " 'data_mill',\n",
              " 'deaths_2012_2018',\n",
              " 'film_locations_in_san_francisco',\n",
              " 'HMRC_exceptions_to_spending_controls_April_to_June_2018',\n",
              " 'HMRC_exceptions_to_spending_controls_April_to_June_2018_facilities',\n",
              " 'HMRC_exceptions_to_spending_controls_April_to_June_2019',\n",
              " 'HMRC_WMI_headcount_and_payroll_data_Mar',\n",
              " 'HMRC_exceptions_to_spending_controls_October_to_December_2017',\n",
              " 'HMRC_Officials_meetings_with_tobacco_stakeholders_Apr_2015_to_Jun',\n",
              " 'HMRC_Officials_meetings_with_tobacco_stakeholders_Apr_2017_to_June',\n",
              " 'HMRC_Officials_meetings_with_tobacco_stakeholders_Apr_2018_to_June',\n",
              " 'HMRC_Officials_meetings_with_tobacco_stakeholders_Jan_2020_to_Mar',\n",
              " 'HMRC_Officials_meetings_with_tobacco_stakeholders_Jul_2014_to_Sept',\n",
              " 'HMRC_Officials_meetings_with_tobacco_stakeholders_Jul_2015_to__Sept',\n",
              " 'HMRC_WMI_headcount_and_payroll_data_May',\n",
              " 'HMRC_WMI_headcount_and_payroll_data_Nov',\n",
              " 'immigration_records',\n",
              " 'ipopayments',\n",
              " 'job_pay_scales',\n",
              " 'lane_description',\n",
              " 'mines',\n",
              " 'minister_meetings',\n",
              " 'prescribing',\n",
              " 'monthly_data_feed',\n",
              " 'new_york_city_restaurant_inspection_results',\n",
              " 'oil_and_gas_summary_production_data_1967_1999',\n",
              " 'practice_reference',\n",
              " 'psyckes_antipsychotic_polypharmacy_quality_indicators_beginning_2012',\n",
              " 'purchasing_card',\n",
              " 'report_card_discipline_for_2015_16',\n",
              " 'senior_officials_expenses',\n",
              " 'stockport_contracts',\n",
              " 'time_spent_watching_vcr_movies',\n",
              " 'tuition_assistance_program_tap_recipients',\n",
              " 'wholesale_markets',\n",
              " 'workforce_management_information',\n",
              " 'ydn_spending_data']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "table_dir = \"datalake\"\n",
        "all_tables = os.listdir(table_dir)\n",
        "table_sets = [ s for s in dict.fromkeys( [ \"_\".join(f.split(\"_\")[:-1]) for f in all_tables ] ) if s ]\n",
        "table_sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfav3ZN0ouh2"
      },
      "source": [
        "# Valentine Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGKsme9czu-g"
      },
      "source": [
        "## Setup Matchers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtqmJZA1zyR4"
      },
      "outputs": [],
      "source": [
        "# Store the constructor of each matcher type by key, which also corresponds to the output dicts below\n",
        "matcher_builders = {\n",
        "    \"coma_opt_matcher\" : lambda : Coma(strategy=\"COMA_OPT\"),            # COMA (schema based matching)\n",
        "    \"coma_opt_inst_matcher\" : lambda : Coma(strategy=\"COMA_OPT_INST\"),  # COMA (schema and instance based matching)\n",
        "    \"cupid_matcher\" : lambda : Cupid(),                                 # Cupid\n",
        "    \"distr_based_matcher\" : lambda : DistributionBased(),               # DistributionBased\n",
        "    \"jaccard_matcher\" : lambda : JaccardLevenMatcher(),                 # JaccardLevenMatcher\n",
        "    \"sim_flooding_matcher\" : lambda : SimilarityFlooding()              # SimilarityFlooding\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8lzNPrd1FRg"
      },
      "source": [
        "## Setup Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ81R5uf1TgV"
      },
      "outputs": [],
      "source": [
        "# Store the results of each matcher\n",
        "matcher_res = {\n",
        "    \"coma_opt_matcher\" : [],\n",
        "    \"coma_opt_inst_matcher\" : [],\n",
        "    \"cupid_matcher\" : [],\n",
        "    \"distr_based_matcher\" : [],\n",
        "    \"jaccard_matcher\" : [],\n",
        "    \"sim_flooding_matcher\" : []\n",
        "}\n",
        "\n",
        "# Store the output paths of each matcher\n",
        "matcher_out_dir = \"valentine_experiments\"\n",
        "matcher_out = {\n",
        "    \"coma_opt_matcher\" : \"results__coma_opt.csv\",\n",
        "    \"coma_opt_inst_matcher\" : \"results__coma_opt_inst.csv\",\n",
        "    \"cupid_matcher\" : \"results__cupid.csv\",\n",
        "    \"distr_based_matcher\" : \"results__distribution_based.csv\",\n",
        "    \"jaccard_matcher\" : \"results__jaccard_levenshtein.csv\",\n",
        "    \"sim_flooding_matcher\" : \"results__similarity_flooding.csv\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuHiuvSPrcLZ"
      },
      "source": [
        "## Run All"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjKuqohhreLC"
      },
      "outputs": [],
      "source": [
        "def record_cluster_metrics(cluster_name, dfs, matcher):\n",
        "  '''\n",
        "  Records the results of a matcher on a set of tables.\n",
        "\n",
        "  Params:\n",
        "  cluster_name: prefix of table set, recorded for analysis\n",
        "  dfs: list of dataframes of the table set\n",
        "  matcher: matcher to use\n",
        "  '''\n",
        "  for i1, i2 in list(combinations(range(len(dfs)), 2)):\n",
        "    df1: pd.DataFrame = dfs[i1]\n",
        "    df2: pd.DataFrame = dfs[i2]\n",
        "    ground_truth = get_ground_truth(df1, df2)\n",
        "    matches = valentine_match(df1, df2, matcher_builders[matcher]())\n",
        "    metrics = valentine_metrics.all_metrics(matches, ground_truth)\n",
        "    metrics[\"dataset\"] = cluster_name\n",
        "    matcher_res[matcher].append(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Qs3swERy7mm"
      },
      "outputs": [],
      "source": [
        "def record_all_cluster_metrics(cluster_name, dfs):\n",
        "  '''\n",
        "  Record the results of all matchers on a set of tables.\n",
        "  Note that only the instance-based matchers are currently tested.\n",
        "\n",
        "  Params:\n",
        "  cluster_name: prefix of table set, recorded for analysis\n",
        "  dfs: list of dataframes of the table set\n",
        "  '''\n",
        "  if (len(dfs) == 0):\n",
        "    return\n",
        "  # record_cluster_metrics(cluster_name, dfs, \"coma_opt_matcher\")\n",
        "  # record_cluster_metrics(cluster_name, dfs, \"coma_opt_inst_matcher\")\n",
        "  # record_cluster_metrics(cluster_name, dfs, \"cupid_matcher\")\n",
        "  record_cluster_metrics(cluster_name, dfs, \"distr_based_matcher\")\n",
        "  record_cluster_metrics(cluster_name, dfs, \"jaccard_matcher\")\n",
        "  # record_cluster_metrics(cluster_name, dfs, sim_flooding_matcher)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J3gMsXS4BCM"
      },
      "outputs": [],
      "source": [
        "def save_metrics():\n",
        "  '''\n",
        "  Save the contents of the matcher results out to their respective files.\n",
        "  '''\n",
        "  for matcher, records in matcher_res.items():\n",
        "    df = pd.DataFrame.from_dict(records)\n",
        "    df.to_csv(os.path.join(matcher_out_dir, matcher_out[matcher]), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NvtsiqYdKtR"
      },
      "source": [
        "# Iterate over Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QJiIwk7dWIf"
      },
      "outputs": [],
      "source": [
        "def get_test_set(pre: str) -> list:\n",
        "  '''\n",
        "  Get the test set split, corresponds to the SANTOS benchmark splits.\n",
        "  '''\n",
        "  s = [ t for t in all_tables if t.startswith(pre) ]\n",
        "  if len(s) < 6:\n",
        "    test = s[:1]\n",
        "    train = s[1:-1]\n",
        "    valid = s[-1:]\n",
        "  if len(s) < 8:\n",
        "    test = s[:2]\n",
        "    train = s[2:-2]\n",
        "    valid = s[-2:]\n",
        "  else:\n",
        "    test = s[:2]\n",
        "    train = s[2:6]\n",
        "    valid = s[-2:]\n",
        "  return test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1FXrONMfRlu"
      },
      "outputs": [],
      "source": [
        "TOKEN_CT = 15  # MAX TOKENS SERIALIZED PER COLUMN\n",
        "\n",
        "def get_dfs(table_lst: list) -> list:\n",
        "  '''\n",
        "  Pre-process the tables, corresponsed to the SANTOS pre-preprocessing.\n",
        "\n",
        "  Params:\n",
        "  table_lst: list of table names\n",
        "\n",
        "  Returns:\n",
        "  list of pre-processed dataframes\n",
        "  '''\n",
        "  # raw data\n",
        "  dfs = [ pd.read_csv(os.path.join(table_dir, csv)) for csv in table_lst ]\n",
        "  # drop numeric columns\n",
        "  dfs = [ df.select_dtypes(exclude=['number']) for df in dfs ]\n",
        "  # drop na rows\n",
        "  dfs = [ df.dropna() for df in dfs ]\n",
        "  # sample rows\n",
        "  dfs = [ df.sample(n=TOKEN_CT) for df in dfs if len(df) >= TOKEN_CT ]\n",
        "  # return\n",
        "  return dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrAUgRPbk86C"
      },
      "outputs": [],
      "source": [
        "def get_ground_truth(df1: pd.DataFrame, df2: pd.DataFrame) -> list:\n",
        "  '''\n",
        "  Generate ground truth based on column names.\n",
        "\n",
        "  Params:\n",
        "  df1, df2: dataframes to pair\n",
        "\n",
        "  Returns:\n",
        "  list of tuples representing matching columns, for use with the Valenine matchers\n",
        "  '''\n",
        "  common_cols = set(df1.columns) & set(df2.columns)\n",
        "  return [ (col, col) for col in common_cols ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6B0vRvm3lg",
        "outputId": "d7a856bb-bb98-47b4-bfd3-f4a26e39787c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In cluster: 311_calls_historic_data\n",
            "In cluster: abandoned_wells\n",
            "In cluster: albums\n",
            "In cluster: animal_tag_data\n",
            "In cluster: biodiversity\n",
            "In cluster: business_rates\n",
            "In cluster: cdc_nutrition_physical_activity_and_obesity_legislation\n",
            "In cluster: cihr_co-applicant\n",
            "In cluster: civic_building_locations\n",
            "In cluster: complaint_by_practice\n",
            "In cluster: contributors_parties\n",
            "In cluster: data_mill\n",
            "In cluster: film_locations_in_san_francisco\n",
            "In cluster: HMRC_exceptions_to_spending_controls_April_to_June_2018\n",
            "In cluster: HMRC_exceptions_to_spending_controls_April_to_June_2018_facilities\n",
            "In cluster: HMRC_exceptions_to_spending_controls_April_to_June_2019\n",
            "In cluster: HMRC_WMI_headcount_and_payroll_data_Mar\n",
            "In cluster: HMRC_exceptions_to_spending_controls_October_to_December_2017\n",
            "In cluster: HMRC_Officials_meetings_with_tobacco_stakeholders_Apr_2015_to_Jun\n",
            "In cluster: HMRC_Officials_meetings_with_tobacco_stakeholders_Apr_2017_to_June\n",
            "In cluster: HMRC_Officials_meetings_with_tobacco_stakeholders_Apr_2018_to_June\n",
            "In cluster: HMRC_Officials_meetings_with_tobacco_stakeholders_Jan_2020_to_Mar\n",
            "In cluster: HMRC_Officials_meetings_with_tobacco_stakeholders_Jul_2014_to_Sept\n",
            "In cluster: HMRC_Officials_meetings_with_tobacco_stakeholders_Jul_2015_to__Sept\n",
            "In cluster: HMRC_WMI_headcount_and_payroll_data_May\n",
            "In cluster: HMRC_WMI_headcount_and_payroll_data_Nov\n",
            "In cluster: immigration_records\n",
            "In cluster: ipopayments\n",
            "In cluster: job_pay_scales\n",
            "In cluster: lane_description\n",
            "In cluster: mines\n",
            "In cluster: minister_meetings\n",
            "In cluster: prescribing\n",
            "In cluster: monthly_data_feed\n",
            "In cluster: new_york_city_restaurant_inspection_results\n",
            "In cluster: oil_and_gas_summary_production_data_1967_1999\n",
            "In cluster: practice_reference\n",
            "In cluster: psyckes_antipsychotic_polypharmacy_quality_indicators_beginning_2012\n",
            "In cluster: purchasing_card\n",
            "In cluster: report_card_discipline_for_2015_16\n",
            "In cluster: senior_officials_expenses\n",
            "In cluster: stockport_contracts\n",
            "In cluster: time_spent_watching_vcr_movies\n",
            "In cluster: tuition_assistance_program_tap_recipients\n",
            "In cluster: wholesale_markets\n",
            "In cluster: workforce_management_information\n",
            "In cluster: ydn_spending_data\n"
          ]
        }
      ],
      "source": [
        "# MAIN LOOP\n",
        "excluded = {\"deaths_2012_2018\"}  # tables that error when run through Valentine models\n",
        "for pre in table_sets:\n",
        "  if (pre in excluded): continue\n",
        "  print(f\"In cluster: {pre}\")\n",
        "  table_names = get_test_set(pre)\n",
        "  test_dfs = get_dfs(table_names)\n",
        "  record_all_cluster_metrics(pre, test_dfs)\n",
        "  save_metrics()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
